{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY-_Zy_b71lD"
   },
   "source": [
    "# Implementation of MCP Neuron for AND and OR Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fu-YDOe_8GJi",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCP_Neurons_AND(X1, X2, T):\n",
    "  \"\"\"\n",
    "  This functions implements basic AND operations with MCP Neuron for two inputs.\n",
    "  Arguments:\n",
    "  Inputs:\n",
    "  X1 (1 nd array): An array of binary values.\n",
    "  X2 (1 nd array): An array of binary values.\n",
    "  Output:\n",
    "  state_neuron(1D-list): An state of neuron 1 0r 0 for the particular inputs.\n",
    "  \"\"\"\n",
    "  assert len(X1) == len(X2)\n",
    "  ### YOUR CODE HERE ###\n",
    "  # Perform an element wise addition of two input arrays stored in a new array(list):\n",
    "  new_array = []\n",
    "  for x1,x2 in zip(X1,X2):\n",
    "      new_array.append(x1+x2)\n",
    "  # Create a new array to put all the prediction let's name that a state_neuron.\n",
    "  state_neuron = []\n",
    "  # Append 1 in sate_neuron if sum (element) of above list is above Threshold else append 0.\n",
    "  for i in range(len(new_array)):\n",
    "      if new_array[i] >= T:\n",
    "          state_neuron.append(1)\n",
    "      else:\n",
    "          state_neuron.append(0)\n",
    "  return state_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2-lKfat8ocN",
    "outputId": "7b06a952-31d4-49c4-b36c-994bac9f413d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of AND gate for inputs [0, 0, 1, 1] and [0, 1, 0, 1] with threshold 2: [0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Example usage for MCP_Neurons_AND function\n",
    "X1 = [0, 0, 1, 1]\n",
    "X2 = [0, 1, 0, 1]\n",
    "T = 2  # Threshold value\n",
    "\n",
    "# Call the MCP_Neurons_AND function\n",
    "result = MCP_Neurons_AND(X1, X2, T)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Output of AND gate for inputs {X1} and {X2} with threshold {T}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7xaMXlLT9FHC"
   },
   "outputs": [],
   "source": [
    "def MCP_Neurons_OR(X1, X2, T):\n",
    "    \"\"\"\n",
    "    This function implements basic OR operations with MCP Neuron for two inputs.\n",
    "    Arguments:\n",
    "    Inputs:\n",
    "    X1 (1D array): An array of binary values.\n",
    "    X2 (1D array): An array of binary values.\n",
    "    Output:\n",
    "    state_neuron (1D list): The state of the neuron (1 or 0) for the particular inputs.\n",
    "    \"\"\"\n",
    "    assert len(X1) == len(X2)\n",
    "    ### YOUR CODE HERE ###\n",
    "    # Perform an element wise addition of two input arrays stored in a new array(list):\n",
    "    new_array = []\n",
    "    for x1,x2 in zip(X1,X2):\n",
    "        new_array.append(x1+x2)\n",
    "    # Create a new array to put all the prediction let's name that a state_neuron.\n",
    "    state_neuron = []\n",
    "    # Append 1 in sate_neuron if sum (element) of above list is above Threshold else append 0.\n",
    "    for i in range(len(new_array)):\n",
    "        if new_array[i] >= T:\n",
    "            state_neuron.append(1)\n",
    "        else:\n",
    "            state_neuron.append(0)\n",
    "    return state_neuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6H-YOy268_Jo",
    "outputId": "dacbda9b-185b-46d8-ac5e-eb0287a99ddf",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of OR gate for inputs [0, 0, 1, 1] and [0, 1, 0, 1] with threshold 1: [0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Example usage for MCP_Neurons_OR function\n",
    "X1 = [0, 0, 1, 1]\n",
    "X2 = [0, 1, 0, 1]\n",
    "T = 1  # Threshold value for OR gate\n",
    "\n",
    "# Call the MCP_Neurons_OR function\n",
    "result_or = MCP_Neurons_OR(X1, X2, T)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Output of OR gate for inputs {X1} and {X2} with threshold {T}: {result_or}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Apa9bfLIFJHe"
   },
   "source": [
    "# Implementation for 0 Vs. 1 Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iom83mGLFP_1"
   },
   "source": [
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py:25\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     IS64,\n\u001b[0;32m     19\u001b[0m     PY39,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     PYPY,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     is_numpy_dev,\n\u001b[0;32m     27\u001b[0m     np_version_under1p21,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     pa_version_under7p0,\n\u001b[0;32m     31\u001b[0m     pa_version_under8p0,\n\u001b[0;32m     32\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     33\u001b[0m     pa_version_under11p0,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_function_name\u001b[39m(f: F, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m F:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[0;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Appender,\n\u001b[0;32m      4\u001b[0m     Substitution,\n\u001b[0;32m      5\u001b[0m     cache_readonly,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     hash_array,\n\u001b[0;32m     10\u001b[0m     hash_pandas_object,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     Any,\n\u001b[0;32m      8\u001b[0m     Callable,\n\u001b[0;32m      9\u001b[0m     Mapping,\n\u001b[0;32m     10\u001b[0m     cast,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     F,\n\u001b[0;32m     17\u001b[0m     T,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     NaT,\n\u001b[0;32m     16\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     iNaT,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7rkW58ct9IYq",
    "outputId": "15351fcc-8af8-4741-9486-d8521c2e785a",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_0_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_0_and_1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Add the correct file path if necessary\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract features and labels\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m df_0_1\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# 784 pixels\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_0_1 = pd.read_csv(\"mnist_0_and_1.csv\")  # Add the correct file path if necessary\n",
    "\n",
    "# Extract features and labels\n",
    "X = df_0_1.drop(columns=[\"label\"]).values  # 784 pixels\n",
    "y = df_0_1[\"label\"].values  # Labels (0 or 1)\n",
    "\n",
    "# Check the shape of the features and labels\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Label vector shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlq0EY2jHheD"
   },
   "source": [
    "### Viewing the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "XKY2qjhCHAZ7",
    "outputId": "2bbc962a-b272-4795-a839-f7b96250c52f",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate images for label 0 and label 1\n",
    "images_0 = X[y == 0]  # Get all images with label 0\n",
    "images_1 = X[y == 1]  # Get all images with label 1\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "\n",
    "# Check if the arrays have the required amount of data\n",
    "if len(images_0) < 5 or len(images_1) < 5:\n",
    "    print(\"Error: Not enough images in images_0 or images_1 to plot 5 images.\")\n",
    "else:\n",
    "    for i in range(5):\n",
    "        # Plot digit 0\n",
    "        axes[0, i].imshow(images_0[i].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[0, i].set_title(\"Label: 0\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        # Plot digit 1\n",
    "        axes[1, i].imshow(images_1[i].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[1, i].set_title(\"Label: 1\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "    plt.suptitle(\"First 5 Images of 0 and 1 from MNIST Subset\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyM34tbHIqGi"
   },
   "source": [
    "## Step - 2 - Initializing the Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMsXaZ38HfBI",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "weights = np.zeros(X.shape[1])  # 784 weights (one for each pixel)\n",
    "bias = 0\n",
    "learning_rate = 0.1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvraDxaeRVeo"
   },
   "source": [
    "## Step - 3 - Make a Decision function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uVj75txLWQi",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decision_function(X, weights, bias):\n",
    "    \"\"\"\n",
    "    Compute the predicted labels for the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features (input data) as a numpy array of shape (n_samples, n_features)\n",
    "    - weights: Updated weights after training\n",
    "    - bias: Updated bias after training\n",
    "\n",
    "    Returns:\n",
    "    - y_pred_all: The predicted labels for the input data\n",
    "    \"\"\"\n",
    "    predictions = np.dot(X, weights) + bias\n",
    "    #####Your Code Here############  # Activation function (step function)\n",
    "    y_pred_all = np.where(predictions>=0, 1, 0)\n",
    "    return y_pred_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVZNGyRdI4I4"
   },
   "source": [
    "## Step - 3 - Implement the Perceptron Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dg1ocrycJWpA",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_perceptron(X, y, weights, bias, learning_rate=0.1, epochs=100):\n",
    "    \"\"\"\n",
    "    Train the perceptron using the Perceptron Learning Algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features (input data) as a numpy array of shape (n_samples, n_features)\n",
    "    - y: Labels (true output) as a numpy array of shape (n_samples,)\n",
    "    - weights: Initial weights as a numpy array of shape (n_features,)\n",
    "    - bias: Initial bias value (scalar)\n",
    "    - learning_rate: Learning rate for weight updates (default is 0.1)\n",
    "    - epochs: Number of iterations to train the model (default is 100)\n",
    "\n",
    "    Returns:\n",
    "    - weights: Updated weights after training\n",
    "    - bias: Updated bias after training\n",
    "    - accuracy: Total correct prediction.\n",
    "    \"\"\"\n",
    "    # Step 3: Perceptron Learning Algorithm\n",
    "    # Your Code here#\n",
    "    n_sample = X.shape[0]\n",
    "    for epoch in range(epochs):\n",
    "        correct_prediction = 0\n",
    "        for i in range(n_sample):\n",
    "            predict = np.dot(X[i], weights) + bias\n",
    "            y_pred = 1 if predict >= 0 else 0\n",
    "\n",
    "            if y_pred == y[i]:\n",
    "                correct_prediction += 1\n",
    "\n",
    "            error = y[i] - y_pred\n",
    "            weights += learning_rate * error * X[i]\n",
    "            bias += learning_rate * error\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"Epoch {epoch}: Accuracy = {correct_prediction/n_sample:.4f}\")\n",
    "\n",
    "    accuracy = correct_prediction / n_sample\n",
    "\n",
    "\n",
    "    return weights, bias, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Va6AGI6iMAG9"
   },
   "source": [
    "## Training the Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cn8XBYuZLswI",
    "outputId": "68bd509b-6ae3-4347-9bc5-8bc1ea1bcdf2"
   },
   "outputs": [],
   "source": [
    "# After training the model with the perceptron_learning_algorithm\n",
    "weights, bias, accuracy = train_perceptron(X, y, weights, bias)\n",
    "\n",
    "# Evaluate the model using the new function\n",
    "print(\"The Final Accuracy is: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SLq1jbSMKPm"
   },
   "source": [
    "## Step 5: Visualize Misclassified Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAMz1RPGMN_A",
    "outputId": "5795b25f-9a63-4815-81bb-f541c046df6f"
   },
   "outputs": [],
   "source": [
    "# Get predictions for all data points\n",
    "predictions = np.dot(X, weights) + bias\n",
    "y_pred = np.where(predictions >= 0, 1, 0)\n",
    "\n",
    "# Calculate final accuracy\n",
    "final_accuracy = np.mean(y_pred == y)\n",
    "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Step 5: Visualize Misclassified Images\n",
    "misclassified_idx = np.where(y_pred != y)[0]\n",
    "if len(misclassified_idx) > 0:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "    for ax, idx in zip(axes.flat, misclassified_idx[:10]):  # Show 10 misclassified images\n",
    "        ax.imshow(X[idx].reshape(28, 28), cmap=\"gray\")\n",
    "        ax.set_title(f\"Pred: {y_pred[idx]}, True: {y[idx]}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(\"Misclassified Images\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"All images were correctly classified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeEDo-9gNknE"
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_3_5 = pd.read_csv(\"mnist_3_and_5.csv\")  # Add the correct file path if necessary\n",
    "\n",
    "# Extract features and labels\n",
    "X = df_3_5.drop(columns=[\"label\"]).values  # 784 pixels\n",
    "y = df_3_5[\"label\"].values  # Labels (3 or 5)\n",
    "\n",
    "# Check the shape of the features and labels\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Label vector shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate images for label 0 and label 1\n",
    "images_3 = X1[y1 == 3]  # Get all images with label 0\n",
    "images_5 = X1[y1 == 5]  # Get all images with label 1\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "\n",
    "# Check if the arrays have the required amount of data\n",
    "if len(images_0) < 5 or len(images_1) < 5:\n",
    "    print(\"Error: Not enough images in images_0 or images_1 to plot 5 images.\")\n",
    "else:\n",
    "    for i in range(5):\n",
    "        # Plot digit 0\n",
    "        axes[0, i].imshow(images_3[i].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[0, i].set_title(\"Label: 3\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        # Plot digit 1\n",
    "        axes[1, i].imshow(images_5[i].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[1, i].set_title(\"Label: 5\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "    plt.suptitle(\"First 5 Images of 3 and 5 from MNIST Subset\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= np.zeros(X.shape[1])  # 784 weights (one for each pixel)\n",
    "bias = 0\n",
    "learning_rate = 0.1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function(X, weights, bias):\n",
    "    \"\"\"\n",
    "    Compute the predicted labels for the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features (input data) as a numpy array of shape (n_samples, n_features)\n",
    "    - weights: Updated weights after training\n",
    "    - bias: Updated bias after training\n",
    "\n",
    "    Returns:\n",
    "    - y_pred_all: The predicted labels for the input data\n",
    "    \"\"\"\n",
    "    predictions = np.dot(X, weights) + bias\n",
    "    #####Your Code Here############  # Activation function (step function)\n",
    "    y_pred_all = np.where(predictions>=0, 5, 3)\n",
    "    return y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X, y, weights, bias, learning_rate=0.1, epochs=100):\n",
    "    \"\"\"\n",
    "    Train the perceptron using the Perceptron Learning Algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features (input data) as a numpy array of shape (n_samples, n_features)\n",
    "    - y: Labels (true output) as a numpy array of shape (n_samples,)\n",
    "    - weights: Initial weights as a numpy array of shape (n_features,)\n",
    "    - bias: Initial bias value (scalar)\n",
    "    - learning_rate: Learning rate for weight updates (default is 0.1)\n",
    "    - epochs: Number of iterations to train the model (default is 100)\n",
    "\n",
    "    Returns:\n",
    "    - weights: Updated weights after training\n",
    "    - bias: Updated bias after training\n",
    "    - accuracy: Total correct prediction.\n",
    "    \"\"\"\n",
    "    # Step 3: Perceptron Learning Algorithm\n",
    "    # Your Code here#\n",
    "    n_sample = X.shape[0]\n",
    "    for epoch in range(epochs):\n",
    "        correct_prediction = 0\n",
    "        for i in range(n_sample):\n",
    "            predict = np.dot(X[i], weights) + bias\n",
    "            y_pred = 5 if predict >= 0 else 3\n",
    "\n",
    "            if y_pred == y[i]:\n",
    "                correct_prediction += 1\n",
    "\n",
    "            error = y[i] - y_pred\n",
    "            weights += learning_rate * error * X[i]\n",
    "            bias += learning_rate * error\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"Epoch {epoch}: Accuracy = {correct_prediction/n_sample:.4f}\")\n",
    "\n",
    "    accuracy = correct_prediction / n_sample\n",
    "\n",
    "\n",
    "    return weights, bias, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias, accuracy = train_perceptron(X, y, weights, bias)\n",
    "\n",
    "# Evaluate the model using the new function\n",
    "print(\"The Final Accuracy is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for all data points\n",
    "predictions = np.dot(X, weights) + bias\n",
    "y_pred = np.where(predictions >= 0, 5, 3)\n",
    "\n",
    "# Calculate final accuracy\n",
    "final_accuracy = np.mean(y_pred == y)\n",
    "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Step 5: Visualize Misclassified Images\n",
    "misclassified_idx = np.where(y_pred != y)[0]\n",
    "if len(misclassified_idx) > 0:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "    for ax, idx in zip(axes.flat, misclassified_idx[:10]):  # Show 10 misclassified images\n",
    "        ax.imshow(X[idx].reshape(28, 28), cmap=\"gray\")\n",
    "        ax.set_title(f\"Pred: {y_pred[idx]}, True: {y[idx]}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(\"Misclassified Images\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"All images were correctly classified!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
